{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TextStreamer\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from accelerate import Accelerator\n",
    "import argparse, logging, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LoRA modules\n",
    "from peft.mapping import get_peft_model\n",
    "from peft.tuners.lora import LoraConfig\n",
    "from peft.utils.peft_types import TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class FormattingFunction:\n",
    "    def __init__(self):\n",
    "        self.instruction = \"\"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: {}<|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\\n\\n{}<|eot_id|>\n",
    "        <|end_of_text|>\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, examples):\n",
    "\n",
    "        final_texts = []\n",
    "        for i in tqdm(range(len(examples[\"input\"]))):\n",
    "            final_text = self.instruction.format(\n",
    "                examples[\"input\"][i], examples[\"output\"][i]\n",
    "            )\n",
    "            final_texts.append(final_text)\n",
    "\n",
    "        return final_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model class\n",
    "class ModelInitiator:\n",
    "    def __init__(self, model_checkpoint, tokenizer_checkpoint):\n",
    "        self.model_checkpoint = model_checkpoint\n",
    "        self.tokenizer_checkpoint = tokenizer_checkpoint\n",
    "\n",
    "    def __call__(self):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_checkpoint,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            attn_implementation=\"flash_attention_2\",\n",
    "        )\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_checkpoint)\n",
    "        tokenizer.pad_token = tokenizer.pad_token\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # initialize model\n",
    "    if args.tokenizer == None:\n",
    "        modelInitiator = ModelInitiator(args.model, args.model)\n",
    "    else:\n",
    "        modelInitiator = ModelInitiator(args.model, args.tokenizer)\n",
    "\n",
    "    model, tokenizer = modelInitiator()\n",
    "\n",
    "    # initialize loraconfig\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config=peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    # prepare dataset\n",
    "    train_dataset = MyDataset(args.train_dataset_dir)\n",
    "    eval_dataset = MyDataset(args.eval_dataset_dir)\n",
    "\n",
    "    # initialize training arguments\n",
    "    trainingarguments = TrainingArguments(\n",
    "        output_dir=args.dir, \n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=args.train_batch_size,\n",
    "        per_device_eval_batch_size=args.eval_batch_size,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=1\n",
    "        num_train_epochs=args.epochs,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        metric_for_best_model=\"train_loss\",\n",
    "        load_best_model_at_end=False,\n",
    "        seed=42,\n",
    "        lr_scheduler_type=\"linear\"\n",
    "    )\n",
    "\n",
    "    #preparing others\n",
    "    formattingfunction = FormattingFunction()\n",
    "\n",
    "    # collator_fn = DataCollatorForLanguageModeling(\n",
    "    #     args.tokenizer, mlm=False\n",
    "    # )  # mlm=False: Autoregressive\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=trainingarguments,\n",
    "        train_dataset=train_dataset,\n",
    "        formatting_func = formattingfunction,\n",
    "        max_seq_len = 2048,\n",
    "        tokenizer = tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "types = \"jupyter_inline\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if types == \"argumentparser\":\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--model\", default=None, type=str, required=True)\n",
    "        parser.add_argument(\"--tokenizer\", default=None, type=str, required=False)\n",
    "        parser.add_argument(\"--output_dir\", default=None, type=str, required=True)\n",
    "        parser.add_argument(\"--train_batch_size\", default=None, type=str, required=True)\n",
    "        parser.add_argument(\"--eval_batch_size\", default=None, type=str, required=True)\n",
    "        parser.add_argument(\"--epochs\", default=None, type=str, required=True)\n",
    "        parser.add_argument(\n",
    "            \"--train_dataset_dir\", default=None, type=str, required=True\n",
    "        )\n",
    "        parser.add_argument(\"--eval_dataset_dir\", default=None, type=str, required=True)\n",
    "\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    if types == \"jupyter_inline\":\n",
    "        model_checkpoint = \"\"\n",
    "        tokenizer_checkpoint = \"\"\n",
    "        more_args_value = \"\"\n",
    "        output_dir_value = \"\"\n",
    "        train_batch_size = \"\"\n",
    "        eval_batch_size = \"\"\n",
    "        epochs = \"\"\n",
    "        train_dataset_dir = \"\"\n",
    "        eval_dataset_dir = \"\"\n",
    "\n",
    "        args = argparse.Namespace(\n",
    "            model=model_checkpoint,\n",
    "            tokenizer=tokenizer_checkpoint,\n",
    "            output_dir=output_dir_value,\n",
    "            train_batch_size=train_batch_size,\n",
    "            eval_batch_size=eval_batch_size,\n",
    "            epochs=epochs,\n",
    "            train_dataset_dir=train_dataset_dir,\n",
    "            eval_dataset_dir=eval_dataset_dir,\n",
    "        )\n",
    "\n",
    "    if types in [\"argumentparser\", \"jupyter_inline\"]:\n",
    "        main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00044721359549995795"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.sqrt(2e-5 * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00447213595499958"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
