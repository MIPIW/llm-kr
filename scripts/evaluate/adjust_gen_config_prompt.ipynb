{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de882b5-e237-406c-9419-2b021dda7e9e",
   "metadata": {},
   "source": [
    "# 생성옵션 & 프롬프트 조정 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4978e311-34c2-4ba8-96d1-67261a512dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adbcf4-7002-47cf-8950-5ef61bcad6f2",
   "metadata": {},
   "source": [
    "## 1. 평가용 프롬프트 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72dff6ab-19d9-483a-866c-2a76f7e9b1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kowiki_v2_leads</td>\n",
       "      <td></td>\n",
       "      <td>황학 (명나라)</td>\n",
       "      <td>황학(黃鶴)는 명나라 중기의 정치인이었다. 자(字)는 명고(鳴臯)이다. 하남성(河南...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doosan_253717</td>\n",
       "      <td></td>\n",
       "      <td>역추력장치</td>\n",
       "      <td>역추력장치는 제트엔진 등의 추력(推力)을 역전시켜서 바퀴의 브레이크 작용을 돕는 장...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gen_generation</td>\n",
       "      <td></td>\n",
       "      <td>여자친구와 5주년을 맞은 남자는 특별한 여행을 계획하고 있다. 남자는 인터넷으로 여...</td>\n",
       "      <td>앱이 화면에 나타나자 남자는 앱을 누른다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gen_closedQA_generation_3</td>\n",
       "      <td>명절을 기념해 지역 내 위기 청소년들에게 물품을 제공한 곳은 어디야</td>\n",
       "      <td>부산 서구 청소년상담복지센터(센터장 유은영) 청소년동반자들은 지난 8일부터 3일간 ...</td>\n",
       "      <td>부산 서구 청소년상담복지센터</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_closedQA_generation_2</td>\n",
       "      <td>맹형규 행안부 장관은 공직기강 확립을 위해 어떤 제목의 서한문을 전 직원들에게 발송했지</td>\n",
       "      <td>행안부 긴급확대간부회의를 개최,「공직기강 확립 및 윤리 실천계획」추진키로 \\n□ 맹...</td>\n",
       "      <td>행안부 가족에게 드리는 글</td>\n",
       "      <td>['행안부 가족에게 드리는 글', '공직기강 확립 실천계획', '청렴서약서', '긴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gen_argument</td>\n",
       "      <td></td>\n",
       "      <td>현재 기술자가 퇴사후에 직권으로 자격증 해임을 하기 위해서는 민법상 규정을 적용해 ...</td>\n",
       "      <td>퇴사시 기술자격증 해임처리방식을 바꾸어야 합니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gen_summarization</td>\n",
       "      <td></td>\n",
       "      <td>해양 녹색기술(green technology)개발은 재생가능하고 환경친화적 방식의 ...</td>\n",
       "      <td>해양 녹색기술개발은 재생가능하고 환경친화적 방식의 과학기술을 해양에서 적용하려는 시...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>translation</td>\n",
       "      <td></td>\n",
       "      <td>This is most likely a result of cultural diffe...</td>\n",
       "      <td>이는 아마도 영국과 미국의 문화적 차이를 반영하는 듯하다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>med_translation</td>\n",
       "      <td></td>\n",
       "      <td>stress fracture</td>\n",
       "      <td>긴장골절 또는 피로골절</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>med_definition</td>\n",
       "      <td></td>\n",
       "      <td>울혈성심장기능상실</td>\n",
       "      <td>심장의 원래 기능 즉 혈액을 말초로 보내는 펌프와 같은 기능이 거의 없어진 ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>law_statute_classification</td>\n",
       "      <td>법 조항</td>\n",
       "      <td>피고인은 (차량번호 1 생략) 포터 화물차의 운전업무에 종사하는 자이다. 피고인은 ...</td>\n",
       "      <td>이 사례에 적용될 수 있는 법조항은 '교통사고 처리특례법 제3조 제1항', '형법 ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>law_openQA</td>\n",
       "      <td></td>\n",
       "      <td>저희 종중은 선산에 20여분의 조상을 모시고 있으나 분묘를 관리할 위토(位土)는 한...</td>\n",
       "      <td>(1) 농지취득에 관하여「농지법」제6조 제1항은 “농지는 자기가 농업경영에 이용하거...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>law_summarization</td>\n",
       "      <td></td>\n",
       "      <td>주문\\n피고인의 상고를 기각한다.\\n\\n이유\\n상고이유를 본다.\\n1. 피고인이 시...</td>\n",
       "      <td>판결문의 핵심 내용만 요약해드리겠습니다: 형법 제16조에 의하여 처벌하지 아니하는 ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>law_statute_content</td>\n",
       "      <td></td>\n",
       "      <td>도로교통법 제12조 제5항 제3호</td>\n",
       "      <td>도로교통법 제12조 제5항 제3호의 내용은 다음과 같습니다: 「도로법」 제2조제2호...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fin_definition</td>\n",
       "      <td></td>\n",
       "      <td>수출보험</td>\n",
       "      <td>해당 용어의 정의는 다음과 같습니다.: 상품수출 시 수출업자가 수입업자의 신용위험,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gen_assistant</td>\n",
       "      <td>당신은 사람들이 정보를 찾을 수 있도록 도와주는 AI 비서입니다.</td>\n",
       "      <td>단순반복동작 작업으로 손, 손가락 또는 손목의 부적절한 작업방법과 자세 등으로 주로...</td>\n",
       "      <td>수근관증후군</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oig-smallchip2-rvsd</td>\n",
       "      <td></td>\n",
       "      <td>왜 그 노래가 '푸른 도나우'라고 불리나요?</td>\n",
       "      <td>푸른 도나우는 아름다움으로 유명한 오스트리아의 강입니다. 오스트리아의 유명한 작곡가...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gen_closedQA_generation_1</td>\n",
       "      <td></td>\n",
       "      <td>맥락: 오산학교(五山學校)는 1907년 12월 남강(南崗) 이승훈(李昇薰)이 민족운...</td>\n",
       "      <td>주어진 질문에 대한 답은 1907년 12월입니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gen_closedQA_classification</td>\n",
       "      <td></td>\n",
       "      <td>문단: 카페 아메리카노 또는 단순히 아메리카노는 에스프레소를 뜨거운 물로 희석하여 ...</td>\n",
       "      <td>입력하신 문단에 대한 질문의 답은 거짓입니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gen_nli</td>\n",
       "      <td></td>\n",
       "      <td>문장1: 73조5000억원 규모로 마련된 금융시장 안정 프로그램에선 12조6000억...</td>\n",
       "      <td>질문자님이 입력하신 첫 번째 문장이 참이라면 두 번째 문장도 참이 됩니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gen_math</td>\n",
       "      <td>산술 연산</td>\n",
       "      <td>어떤 수를 6으로 나누어야 할 것을 잘못하여 곱하였더니 36이 되었습니다. 바르게 ...</td>\n",
       "      <td>해당 문제에 대한 정답은 1입니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gen_sts_classification</td>\n",
       "      <td></td>\n",
       "      <td>난방비 비싼데 추워, 가스비 비싼데 감기 걸리겠어</td>\n",
       "      <td>두 문장은 같은 상황을 묘사하고 있습니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gen_news_classification_option</td>\n",
       "      <td>이 무슨 카테고리에 속하는 지 알려주세요.</td>\n",
       "      <td>언론사들은 이 번 대통령의 방중에 대하여 국민들이 스스로 판단하고 결정할 권리를 방...</td>\n",
       "      <td>문화/예술/체육/언론</td>\n",
       "      <td>선택지:\\n&amp;&amp;정치개혁&amp;&amp;문화/예술/체육/언론&amp;&amp;인권/성평등&amp;&amp;보건복지&amp;&amp;기타&amp;&amp;미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gen_news_classification</td>\n",
       "      <td></td>\n",
       "      <td>LH 아파트 최근 3년간 공급 아파트에서 하자 2만4천여건</td>\n",
       "      <td>입력하신 기사의 주제는 사회입니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gen_sentiment_classification</td>\n",
       "      <td></td>\n",
       "      <td>개인적인 의견이지만 끝에 뭔가 큰 반전이 있을줄 알고 봐서 그런지 그냥 밍숭맹숭하네...</td>\n",
       "      <td>이 텍스트의 감정지수는 부정적입니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gen_polysemy_classification</td>\n",
       "      <td></td>\n",
       "      <td>단어: 성화, 문장1: 새살림을 차렸으니 집들이하라는 주변의 [성화]가 대단하다.,...</td>\n",
       "      <td>해당 단어는 주어진 두 문장에서 같은 의미를 가지고 있습니다.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              task  \\\n",
       "0                  kowiki_v2_leads   \n",
       "1                    doosan_253717   \n",
       "2                   gen_generation   \n",
       "3        gen_closedQA_generation_3   \n",
       "4        gen_closedQA_generation_2   \n",
       "5                     gen_argument   \n",
       "6                gen_summarization   \n",
       "7                      translation   \n",
       "8                  med_translation   \n",
       "9                   med_definition   \n",
       "10      law_statute_classification   \n",
       "11                      law_openQA   \n",
       "12               law_summarization   \n",
       "13             law_statute_content   \n",
       "14                  fin_definition   \n",
       "15                   gen_assistant   \n",
       "16             oig-smallchip2-rvsd   \n",
       "17       gen_closedQA_generation_1   \n",
       "18     gen_closedQA_classification   \n",
       "19                         gen_nli   \n",
       "20                        gen_math   \n",
       "21          gen_sts_classification   \n",
       "22  gen_news_classification_option   \n",
       "23         gen_news_classification   \n",
       "24    gen_sentiment_classification   \n",
       "25     gen_polysemy_classification   \n",
       "\n",
       "                                         instruction  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3              명절을 기념해 지역 내 위기 청소년들에게 물품을 제공한 곳은 어디야   \n",
       "4   맹형규 행안부 장관은 공직기강 확립을 위해 어떤 제목의 서한문을 전 직원들에게 발송했지   \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                              법 조항   \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                                     \n",
       "15              당신은 사람들이 정보를 찾을 수 있도록 도와주는 AI 비서입니다.   \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                             산술 연산   \n",
       "21                                                     \n",
       "22                           이 무슨 카테고리에 속하는 지 알려주세요.   \n",
       "23                                                     \n",
       "24                                                     \n",
       "25                                                     \n",
       "\n",
       "                                                input  \\\n",
       "0                                            황학 (명나라)   \n",
       "1                                               역추력장치   \n",
       "2   여자친구와 5주년을 맞은 남자는 특별한 여행을 계획하고 있다. 남자는 인터넷으로 여...   \n",
       "3   부산 서구 청소년상담복지센터(센터장 유은영) 청소년동반자들은 지난 8일부터 3일간 ...   \n",
       "4   행안부 긴급확대간부회의를 개최,「공직기강 확립 및 윤리 실천계획」추진키로 \\n□ 맹...   \n",
       "5   현재 기술자가 퇴사후에 직권으로 자격증 해임을 하기 위해서는 민법상 규정을 적용해 ...   \n",
       "6   해양 녹색기술(green technology)개발은 재생가능하고 환경친화적 방식의 ...   \n",
       "7   This is most likely a result of cultural diffe...   \n",
       "8                                     stress fracture   \n",
       "9                                           울혈성심장기능상실   \n",
       "10  피고인은 (차량번호 1 생략) 포터 화물차의 운전업무에 종사하는 자이다. 피고인은 ...   \n",
       "11  저희 종중은 선산에 20여분의 조상을 모시고 있으나 분묘를 관리할 위토(位土)는 한...   \n",
       "12  주문\\n피고인의 상고를 기각한다.\\n\\n이유\\n상고이유를 본다.\\n1. 피고인이 시...   \n",
       "13                                 도로교통법 제12조 제5항 제3호   \n",
       "14                                               수출보험   \n",
       "15  단순반복동작 작업으로 손, 손가락 또는 손목의 부적절한 작업방법과 자세 등으로 주로...   \n",
       "16                           왜 그 노래가 '푸른 도나우'라고 불리나요?   \n",
       "17  맥락: 오산학교(五山學校)는 1907년 12월 남강(南崗) 이승훈(李昇薰)이 민족운...   \n",
       "18  문단: 카페 아메리카노 또는 단순히 아메리카노는 에스프레소를 뜨거운 물로 희석하여 ...   \n",
       "19  문장1: 73조5000억원 규모로 마련된 금융시장 안정 프로그램에선 12조6000억...   \n",
       "20  어떤 수를 6으로 나누어야 할 것을 잘못하여 곱하였더니 36이 되었습니다. 바르게 ...   \n",
       "21                        난방비 비싼데 추워, 가스비 비싼데 감기 걸리겠어   \n",
       "22  언론사들은 이 번 대통령의 방중에 대하여 국민들이 스스로 판단하고 결정할 권리를 방...   \n",
       "23                   LH 아파트 최근 3년간 공급 아파트에서 하자 2만4천여건   \n",
       "24  개인적인 의견이지만 끝에 뭔가 큰 반전이 있을줄 알고 봐서 그런지 그냥 밍숭맹숭하네...   \n",
       "25  단어: 성화, 문장1: 새살림을 차렸으니 집들이하라는 주변의 [성화]가 대단하다.,...   \n",
       "\n",
       "                                               output  \\\n",
       "0   황학(黃鶴)는 명나라 중기의 정치인이었다. 자(字)는 명고(鳴臯)이다. 하남성(河南...   \n",
       "1   역추력장치는 제트엔진 등의 추력(推力)을 역전시켜서 바퀴의 브레이크 작용을 돕는 장...   \n",
       "2                             앱이 화면에 나타나자 남자는 앱을 누른다.   \n",
       "3                                     부산 서구 청소년상담복지센터   \n",
       "4                                      행안부 가족에게 드리는 글   \n",
       "5                         퇴사시 기술자격증 해임처리방식을 바꾸어야 합니다.   \n",
       "6   해양 녹색기술개발은 재생가능하고 환경친화적 방식의 과학기술을 해양에서 적용하려는 시...   \n",
       "7                    이는 아마도 영국과 미국의 문화적 차이를 반영하는 듯하다.   \n",
       "8                                        긴장골절 또는 피로골절   \n",
       "9       심장의 원래 기능 즉 혈액을 말초로 보내는 펌프와 같은 기능이 거의 없어진 ...   \n",
       "10  이 사례에 적용될 수 있는 법조항은 '교통사고 처리특례법 제3조 제1항', '형법 ...   \n",
       "11  (1) 농지취득에 관하여「농지법」제6조 제1항은 “농지는 자기가 농업경영에 이용하거...   \n",
       "12  판결문의 핵심 내용만 요약해드리겠습니다: 형법 제16조에 의하여 처벌하지 아니하는 ...   \n",
       "13  도로교통법 제12조 제5항 제3호의 내용은 다음과 같습니다: 「도로법」 제2조제2호...   \n",
       "14  해당 용어의 정의는 다음과 같습니다.: 상품수출 시 수출업자가 수입업자의 신용위험,...   \n",
       "15                                             수근관증후군   \n",
       "16  푸른 도나우는 아름다움으로 유명한 오스트리아의 강입니다. 오스트리아의 유명한 작곡가...   \n",
       "17                        주어진 질문에 대한 답은 1907년 12월입니다.   \n",
       "18                          입력하신 문단에 대한 질문의 답은 거짓입니다.   \n",
       "19          질문자님이 입력하신 첫 번째 문장이 참이라면 두 번째 문장도 참이 됩니다.   \n",
       "20                                해당 문제에 대한 정답은 1입니다.   \n",
       "21                            두 문장은 같은 상황을 묘사하고 있습니다.   \n",
       "22                                        문화/예술/체육/언론   \n",
       "23                                입력하신 기사의 주제는 사회입니다.   \n",
       "24                               이 텍스트의 감정지수는 부정적입니다.   \n",
       "25                 해당 단어는 주어진 두 문장에서 같은 의미를 가지고 있습니다.   \n",
       "\n",
       "                                               option  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4   ['행안부 가족에게 드리는 글', '공직기강 확립 실천계획', '청렴서약서', '긴...  \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                                     \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "21                                                     \n",
       "22  선택지:\\n&&정치개혁&&문화/예술/체육/언론&&인권/성평등&&보건복지&&기타&&미...  \n",
       "23                                                     \n",
       "24                                                     \n",
       "25                                                     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv(\"gen_config_prompt_sample.csv\", keep_default_na = False)\n",
    "samples\n",
    "\n",
    "###########\n",
    "# cf. 태스크별 샘플 추출: gen_config_prompt_sample.csv 생성\n",
    "# samples = []\n",
    "\n",
    "# df_train = pd.read_csv(\"../../../node_storage2/data_llm_kr/data_it_train_240724.csv\", keep_default_na = False)\n",
    "\n",
    "# for task in df_train[\"task\"].unique():\n",
    "#     df_train_task = df_train[df_train[\"task\"] == task ] # 특정 태스크에 해당하는 행 중에\n",
    "#     sample = df_train_task.sample(n=1, random_state=1) # 1개 랜덤샘플링\n",
    "#     samples.append(sample)\n",
    "\n",
    "# samples = pd.concat(samples)\n",
    "# samples.to_csv(\"gen_config_prompt_sample.csv\", index=False)\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c11a8b8-35d1-4638-9fe6-1ee9cfe5b694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,\n",
       " task\n",
       " doosan_253717                     228345\n",
       " kowiki_v2_leads                   180000\n",
       " gen_closedQA_generation_3          18000\n",
       " gen_assistant                      18000\n",
       " gen_closedQA_generation_2          13390\n",
       " oig-smallchip2-rvsd                12616\n",
       " med_translation                    12237\n",
       " gen_argument                       11871\n",
       " gen_generation                     11574\n",
       " gen_summarization                   9000\n",
       " law_summarization                   9000\n",
       " translation                         9000\n",
       " law_openQA                          3617\n",
       " med_definition                      2020\n",
       " law_statute_content                  982\n",
       " gen_closedQA_generation_1            900\n",
       " gen_closedQA_classification          900\n",
       " fin_definition                       669\n",
       " gen_news_classification              450\n",
       " gen_nli                              450\n",
       " gen_math                             450\n",
       " gen_sts_classification               450\n",
       " gen_polysemy_classification          450\n",
       " gen_sentiment_classification         450\n",
       " gen_news_classification_option       418\n",
       " law_statute_classification           259\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원 데이터 태스크 전체 목록 \n",
    "# len(df_train[\"task\"].value_counts()), df_train[\"task\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f580da4a-407a-46aa-aa0d-459442a06dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['task', 'instruction', 'input', 'output', 'option'],\n",
       "    num_rows: 26\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas dataframe을 dataset 객체로 변환\n",
    "ds_sample = Dataset.from_pandas(samples)\n",
    "ds_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd30d53a-a9c9-4ce1-8bf6-67e858658734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fin_definition': [['이 개념에 대해 설명해줘. \\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이건 무슨 뜻인가요?', '{output}'],\n",
       "  ['이게 뭔지 간단하게 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이 단어가 의미하는 바가 무엇인지 짧게 설명해주세요.', '{output}'],\n",
       "  ['다음 용어는 무슨 뜻인가요?\\n\\n{input}', '{output}'],\n",
       "  ['다음 용어에 대한 정의를 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 단어 무슨 뜻이야? \\n\\n{input}', '{output}'],\n",
       "  ['다음 단어가 뭔 뜻인지 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 단어가 어떤 의미인지 말해주십시오.\\n\\n{input}', '{output}'],\n",
       "  ['이거 무슨 뜻이야?\\n\\n{input}', '{output}'],\n",
       "  ['이게 뭐야?\\n\\n{input}', '{output}']],\n",
       " 'gen_argument': [['다음 문장의 요지를 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 글은 무슨 내용의 글인지 정리해줘.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이것의 내용을 간략히 설명해주시겠어요?', '{output}'],\n",
       "  ['{input}\\n\\n위 글의 핵심은?', '{output}'],\n",
       "  ['이 문장이 무엇에 관한 내용인지 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음과 같은 문장이 주어졌을 때 핵심 포인트를 알려줄래?\\n\\n{input}', '{output}'],\n",
       "  ['다음 문장의 키워드를 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 문장에서 중요한 부분만 뽑아줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 문장의 요지만 추려서 알려주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_assistant': [['{instruction} \\n\\n{input}', '{output}']],\n",
       " 'gen_closedQA_classification': [['다음과 같이 문단과 질문이 주어졌을 때 질문의 답을 추론해주세요.\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['다음 문단을 고려할 때, 주어진 질문의 답은 무엇인가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 단락을 바탕으로 제시된 질문에 대한 답을 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 문단을 보고 함께 제시된 질문에 답해줄래?\\n\\n{input}', '{output}']],\n",
       " 'gen_closedQA_generation_1': [['이 문서에서 이 질문에 대한 답을 알려줄래?\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['다음과 같은 지문과 문제가 주어졌을 때, 지문을 보고 문제를 풀어줄래?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 문서에 근거해서 질문에 대답해줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 질문의 답을 주어진 문서 속에서 찾아줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 지문을 토대로 다음 문제의 답을 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 독해 문제를 풀고 정답을 말해보세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 문제의 정답은 무엇일까요?\\n\\n{input}', '{output}'],\n",
       "  ['다음 독해 문제를 풀어주세요.\\n\\n{input}', '{output}'],\n",
       "  ['주어진 문제와 지문을 읽고 정답을 맞혀보세요.\\n\\n{input}', '{output}'],\n",
       "  ['아래 문제와 텍스트를 읽고 정답을 맞혀봐.\\n\\n{input}', '{output}'],\n",
       "  ['이 문서에서 이 질문에 대한 답을 알려줄래?\\n\\n{input}', '{output}'],\n",
       "  ['다음과 같은 지문과 문제가 주어졌을 때, 지문을 보고 문제를 풀어줄래?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 문서에 근거해서 질문에 대답해줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 질문의 답을 주어진 문서 속에서 찾아줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 지문을 토대로 다음 문제의 답을 알려줘.\\n\\n{input}', '{output}']],\n",
       " 'gen_closedQA_generation_2': [['{instruction}\\n선택지: {option}\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['{input}\\n\\n{instruction}\\n\\n{option}', '{output}']],\n",
       " 'gen_closedQA_generation_3': [['{instruction}\\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 읽고 아래 질문에 답변해주세요.\\n\\n{input}\\n\\n{instruction}', '{output}'],\n",
       "  ['{instruction}\\n이 질문에 대한 답을 다음 글을 기반으로 해줘.\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n위에 따르면, {instruction}?', '{output}']],\n",
       " 'gen_generation': [['이 글 다음에 올 문장을 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음과 같은 글이 주어졌을 때, 다음 문장을 예상해볼래?\\n\\n{input}', '{output}'],\n",
       "  ['다음 문단 다음에 올 문장을 말해봐..\\n\\n{input}', '{output}'],\n",
       "  ['다음 글 다음에 올 문장을 작성해줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 문단 다음에 올 문장을 작성해주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_math': [['다음 {instruction} 문제의 답을 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 수학 문제 답이 뭐야? \\n\\n{input}', '{output}'],\n",
       "  ['다음 문제 좀 풀어줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 {instruction} 문제 정답이 뭔지 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 수학 문제 답이 무엇인가요?\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n위 {instruction} 문제 답이 뭐야?', '{output}'],\n",
       "  ['{input}\\n\\n풀어줘.', '{output}']],\n",
       " 'gen_news_classification': [['이 신문 기사의 주제를 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음과 같은 뉴스 제목이 주어졌을 때 주제를 맞혀볼래?\\n\\n{input}', '{output}'],\n",
       "  ['다음 뉴스의 토픽을 한 마디로 대답해줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 신문 기사의 토픽을 분류해줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 신문 기사의 주제를 분류해주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_news_classification_option': [['{option}\\n이 중 아래 청원{instruction}\\n\\n{input}',\n",
       "   '이 청원의 분류 또는 카테고리는 다음과 같습니다.: {output}'],\n",
       "  ['아래 글{instruction}\\n{option}\\n\\n{input}', '이 글의 카테고리는 {output} 입니다.'],\n",
       "  ['다음 내용{instruction}\\n{option}\\n\\n{input}', '이 글의 카테고리는 {output} 입니다.'],\n",
       "  ['다음 글{instruction}\\n{option}\\n\\n{input}', '이 글의 카테고리는 {output} 입니다.'],\n",
       "  ['{option}\\n아래 내용{instruction}\\n\\n{input}', '이 글의 카테고리는 {output} 입니다.'],\n",
       "  ['다음 청원{instruction}\\n{option}\\n\\n{input}',\n",
       "   '이 청원의 분류 또는 카테코리는 다음과 같습니다.: {output}']],\n",
       " 'gen_nli': [['다음과 같이 두 문장이 주어졌을 때 둘의 관계를 추론해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장은 논리적으로 어떤 관계인가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 문장의 논리적인 관계를 파악해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장의 관계를 분석해봐.\\n\\n{input}', '{output}'],\n",
       "  ['아래 제시한 두 문장의 논리적인 관계를 추론해줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장은 논리적으로 어떤 관계인가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 문장의 논리적인 관계를 파악해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장의 관계를 분석해봐.\\n\\n{input}', '{output}'],\n",
       "  ['아래 제시한 두 문장의 논리적인 관계를 추론해줘.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n주어진 두 문장이 어떤 관계인지 추론해보세요.', '{output}'],\n",
       "  ['다음과 같이 전제와 가설이 주어졌을 때 둘의 관계를 추론해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장은 논리적으로 어떤 관계인가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 문장의 논리적인 관계를 파악해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장의 관계를 분석해봐. \\n\\n{input}', '{output}'],\n",
       "  ['아래 제시한 두 문장의 논리적인 관계를 추론해줘.\\n\\n{input}', '{output}']],\n",
       " 'gen_polysemy_classification': [['다음과 같이 두 문장이 주어졌을 때 입력된 단어가 같은 의미로 쓰이는지 파악해주세요.\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['다음 두 문장 속에서 주어진 단어가 같은 의미야?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 문장에서 입력된 단어가 같은 의미를 가지는지 알려주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_sentiment_classification': [['다음 문장이 긍정적인 문장인지 부정적인 문장인지 알려줘.\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['이 문장에 대해 긍정/부정으로 분류해줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 문장이 긍정적이야, 부정적이야?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 문장을 긍정 혹은 부정으로 분류해줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 리뷰의 전체적인 태도를 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 글을 쓴 사람은 만족해, 불만족해?\\n\\n{input}', '{output}'],\n",
       "  ['이 기사의 내용은 긍정적이야, 부정적이야?\\n\\n{input}', '{output}'],\n",
       "  ['이 글은 행복한 내용이야?\\n\\n{input}', '{output}'],\n",
       "  ['이 글의 분위기를 긍부정으로 나눠주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_sts_classification': [['다음 두 문장이 같은 의미를 나타내나요?\\n\\n{input}', '{output}'],\n",
       "  ['이 두 문장이 유사한 뜻일까?\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장의 의미는 같나요 다른가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 상황이 동일한 상황인가요? \\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장은 패러프레이즈 관계인가요?\\n\\n{input}', '{output}'],\n",
       "  ['이 두 문장이 의미적으로 유사한지 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 두 문장의 의미는 서로 비슷한가요?\\n\\n{input}', '{output}'],\n",
       "  ['주어진 두 문장의 뜻이 서로 비슷한지 판단해줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 두 문장이 사실상 같은 말을 하고 있는지 알려주세요.\\n\\n{input}', '{output}']],\n",
       " 'gen_summarization': [['다음 글에서 핵심만 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['해당 문서에서 중요한 내용을 추려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 글을 요약해줄 수 있어?\\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 짧게 요약해줄 수 있나요?\\n\\n{input}', '{output}'],\n",
       "  ['다음 글에서 핵심만 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 짧게 요약해줄 수 있나요?\\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 요약해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 글에서 핵심만 요약해줄 수 있어요?\\n\\n{input}', '{output}'],\n",
       "  ['이 글을 짧게 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 글을 요약해줄 수 있어?\\n\\n{input}', '{output}'],\n",
       "  ['이 기사에서 핵심 문장만 뽑아줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음과 같은 기사가 주어졌을 때 핵심 포인트를 알려줄래?\\n\\n{input}', '{output}'],\n",
       "  ['다음 기사를 간추려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 기사에서 중요한 내용만 뽑아줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 기사의 요점만 추려서 알려주세요.\\n\\n{input}', '{output}']],\n",
       " 'law_openQA': [['{input}\\n\\n해당 질문에 대해 법률 자문을 해주세요.', '{output}'],\n",
       "  ['다음 상황을 법적으로 해결할 수 있는 방법을 알려주십시오. \\n\\n{input}', '{output}'],\n",
       "  ['주어지는 질문에 대한 법적 조언을 부탁드립니다.\\n\\n{input}', '{output}'],\n",
       "  ['다음 상황에 대해 법률 상담을 받고자 합니다. \\n\\n{input}', '{output}'],\n",
       "  ['법률 지식을 동원하여 다음 질문에 대한 해결책을 제시해주세요. \\n\\n{input}', '{output}'],\n",
       "  ['제시된 상황에 대해 참고할 수 있는 법률 내용을 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 질문에 대한 법률적 조언을 해주십시오.\\n\\n{input}', '{output}'],\n",
       "  ['다음 질문에 도움이 될만한 법령 정보를 제공해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['해당 상황을 해결하기 위해 필요한 법률 지식을 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  [\"{input}\\n\\n '이에 대해 법적으로 어떻게 대응하면 좋을지 조언해주세요.\", '{output}']],\n",
       " 'law_statute_classification': [['아래 사건의 사실 관계를 읽고 어떤 {instruction}이 적용될 수 있는지 알려줘.\\n\\n{input}',\n",
       "   '{output}'],\n",
       "  ['다음과 같은 상황에서 적용될 수 있는 {instruction}이 뭔가요?\\n\\n{input}', '{output}'],\n",
       "  ['판결문의 일부를 읽고 관련성이 있는 {instruction}이 어떤 것인지 말해봐.\\n\\n{input}', '{output}'],\n",
       "  ['이 사건에서 무슨 {instruction}이 적용될 수 있는지 알려주십시오.\\n\\n{input}', '{output}']],\n",
       " 'law_statute_content': [['다음 법의 내용이 뭔지 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['이 법은 어떤 내용인가요?\\n\\n{input}', '{output}'],\n",
       "  ['이 법에 대해서 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['아래 법이 무슨 내용인지 설명 부탁해.\\n\\n{input}', '{output}'],\n",
       "  ['이것은 뭐에 관한 법이지?\\n\\n{input}', '{output}']],\n",
       " 'law_summarization': [['이 판결문 핵심만 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 판결문에서 주요 내용만 간략하게 정리해줘.\\n\\n{input}', '{output}'],\n",
       "  ['아래 판결문에 대해 요약본 좀 줄 수 있어?\\n\\n{input}', '{output}'],\n",
       "  ['판결문 짧게 압축 설명해주세요.\\n\\n{input}', '{output}']],\n",
       " 'med_definition': [['이 개념에 대해 설명해줘. \\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이건 무슨 뜻인가요?', '{output}'],\n",
       "  ['이게 뭔지 간단하게 요약해줘.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이 단어가 의미하는 바가 무엇인지 짧게 설명해주세요.', '{output}'],\n",
       "  ['다음 용어는 무슨 뜻인가요?\\n\\n{input}', '{output}'],\n",
       "  ['다음 용어에 대한 정의를 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 단어 무슨 뜻이야? \\n\\n{input}', '{output}'],\n",
       "  ['다음 단어가 뭔 뜻인지 알려줘.\\n\\n{input}', '{output}'],\n",
       "  ['다음 단어가 어떤 의미인지 말해주십시오.\\n\\n{input}', '{output}'],\n",
       "  ['이거 무슨 뜻이야?\\n\\n{input}', '{output}'],\n",
       "  ['이게 뭐야?\\n\\n{input}', '{output}']],\n",
       " 'med_translation': [['{input}\\nto Korean:', '{output}'],\n",
       "  ['이 글을 한국어로 번역해줘. \\n\\n{input}', '{output}'],\n",
       "  ['이거 한국어로 번역 좀 해주세요. \\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 한글로 써줄 수 있어? \\n\\n{input}', '{output}'],\n",
       "  [\"User:{input}\\n\\n What's this in Korean?\", '{output}'],\n",
       "  ['User:{input}\\n\\n Can you translate English into Korean?', '{output}'],\n",
       "  ['User:{input}\\n\\n Translate this to Korean.', '{output}'],\n",
       "  ['Please rewrite this in Korean. \\n\\n{input}', '{output}']],\n",
       " 'kowiki_v2_leads': [['이 개념에 대해 설명해줘. \\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이 용어의 뜻을 알려주세요.', '{output}'],\n",
       "  ['이게 뭔지 가르쳐주세요.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n에 대해 개괄적으로 설명해줘.', '{output}'],\n",
       "  ['다음 단어를 정의 중심으로 설명해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 개념을 요점 위주로 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 개념이 무엇인지 가르쳐줄래? \\n\\n{input}', '{output}']],\n",
       " 'doosan_253717': [['이 개념에 대해 설명해줘. \\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n이 용어의 뜻을 알려주세요.', '{output}'],\n",
       "  ['이게 뭔지 가르쳐주세요.\\n\\n{input}', '{output}'],\n",
       "  ['{input}\\n\\n에 대해 개괄적으로 설명해줘.', '{output}'],\n",
       "  ['다음 단어를 정의 중심으로 설명해주세요.\\n\\n{input}', '{output}'],\n",
       "  ['다음 개념을 요점 위주로 알려주세요.\\n\\n{input}', '{output}'],\n",
       "  ['이 개념이 무엇인지 가르쳐줄래? \\n\\n{input}', '{output}']],\n",
       " 'translation': [['{input}\\nto Korean:', '{output}'],\n",
       "  ['이 글을 한국어로 번역해줘. \\n\\n{input}', '{output}'],\n",
       "  ['이거 한국어로 번역 좀 해주세요. \\n\\n{input}', '{output}'],\n",
       "  ['다음 글을 한글로 써줄 수 있어? \\n\\n{input}', '{output}'],\n",
       "  [\"User:{input}\\n\\n What's this in Korean?\", '{output}'],\n",
       "  ['User:{input}\\n\\n Can you translate English into Korean?', '{output}'],\n",
       "  ['User:{input}\\n\\n Translate this to Korean.', '{output}'],\n",
       "  ['Please rewrite this in Korean. \\n\\n{input}', '{output}']],\n",
       " 'oig-smallchip2-rvsd': [['{instruction} \\n\\n{input}', '{output}']]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 템플릿 파일 불러오기\n",
    "with open('../../../node_storage2/data_llm_kr/instruction_template_240724.json', 'r') as f:\n",
    "    templates = json.load(f)\n",
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7be13d8-d7f5-409d-8b19-8e92e3154148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 포맷팅\n",
    "\n",
    "# 1. 태스크별 질문 다르게 설정\n",
    "def apply_task_templates(example):\n",
    "    # 태스크별로 다른 질문 적용하기 위한 추가 함수.\n",
    "    # 예시: input_text= \"다음 내용{instruction}\\n{option}\\n\\n{input}\", output_text= \"이 글의 카테고리는 {output} 입니다.\"\"\n",
    "    random_template = templates[example['task']][0] # 여러 템플릿 중 랜덤하게 선택하는 대신 (random.choice(templates[example['task']]) ) # 템플릿 중 0번째 항목 사용\n",
    "    input_text = random_template[0]\n",
    "    output_text = random_template[1]\n",
    "\n",
    "    _instruction = example['instruction'].strip() if example['instruction'].strip() else ''\n",
    "    _input = example['input'].strip() if example['input'].strip() else ''\n",
    "    _output = example['output'].strip() if example['output'].strip() else ''\n",
    "    _option = example['option'].strip() if example['option'].strip() else ''\n",
    "    \n",
    "    input_text = input_text.replace('{instruction}', _instruction)\n",
    "    input_text = input_text.replace('{input}', _input)\n",
    "    input_text = input_text.replace('{option}', _option)\n",
    "    output_text = output_text.replace('{output}', _output)\n",
    "        \n",
    "    io_task_template_applied = (input_text, output_text)\n",
    "    return io_task_template_applied\n",
    "    \n",
    "\n",
    "# 2. assistant 답변 생성용 템플릿 적용\n",
    "  # 훈련 시에 사용하는 템플릿에서 output 부분 이후 제거\n",
    "def formatting_func(examples):\n",
    "    \n",
    "    model2template_gen = {\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\": \"\"\"\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: {}<|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\\n\\n\"\"\", # post_processor adds '<|begin_of_text|>'\n",
    "        \"google/gemma-2-9b-it\": \"\"\"\n",
    "        <start_of_turn>model\n",
    "        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<end_of_turn>\n",
    "        <start_of_turn>user\n",
    "        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: {}<end_of_turn>\n",
    "        <start_of_turn>model\\n\"\"\", # post_processor adds '<bos>'\n",
    "        \"Qwen/Qwen2-7B-Instruct\": \"\"\"\n",
    "        <|im_start|>system\n",
    "        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.\\n<|im_end|>\n",
    "        <|im_start|>user\n",
    "        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: {}<|im_end|>\n",
    "        <|im_start|>system\\n\"\"\"\n",
    "    }\n",
    "    \n",
    "    model2template_gen = {k:v.strip() for k, v in model2template_gen.items()}\n",
    "    template = model2template_gen[model_name_or_path]\n",
    "    \n",
    "    formatted = []\n",
    "    for i in range(len(examples[\"input\"])):\n",
    "        _input, _output = apply_task_templates(examples[i])\n",
    "        formatted.append(template.format(_input)) # 훈련 시에는 template.format(_input, _output) \n",
    "        \n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd90cec0-f175-42ee-9bef-1152614b8781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'kowiki_v2_leads',\n",
       " 'instruction': '',\n",
       " 'input': '황학 (명나라)',\n",
       " 'output': '황학(黃鶴)는 명나라 중기의 정치인이었다. 자(字)는 명고(鳴臯)이다. 하남성(河南省) 개봉부(開封府) 기현(杞縣) 출신이다.',\n",
       " 'option': ''}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bac9c3c-6bb5-4271-8523-04c030fd11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 어떤 모델 템플릿 적용할지   # \"google/gemma-2-9b-it\" # \"Qwen/Qwen2-7B-Instruct\"\n",
    "ds_sample = formatting_func(ds_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d7709f-1710-4e53-90ec-54c4782e3247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 개념에 대해 설명해줘. \\n\\n황학 (명나라)<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 개념에 대해 설명해줘. \\n\\n역추력장치<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 글 다음에 올 문장을 알려줘.\\n\\n여자친구와 5주년을 맞은 남자는 특별한 여행을 계획하고 있다. 남자는 인터넷으로 여행 장소를 검색하고 정보를 수집하기 시작한다. 그리고 정보를 찾다가 알아낸 여행 관련 앱을 태블릿에 다운받는다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " \"<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 명절을 기념해 지역 내 위기 청소년들에게 물품을 제공한 곳은 어디야\\n\\n부산 서구 청소년상담복지센터(센터장 유은영) 청소년동반자들은 지난 8일부터 3일간 민족의 큰 명절인 설날을 맞아 청소년들에게 '설날 KIT'를 직접 전달했다. \\n\\n \\n\\n '설날 KIT'는 가족들과 함께 즐길 수 있는 추억의 과자 종합 세트와 전통 민속놀이인 윷놀이 세트, 손 소독제·마스크 및 일회용 체온계 등이 포함된 코로나19 백신 KIT로 구성되어 있다. \\n\\n \\n\\n '설날 KIT'를 전달받은 청소년은 “설날인데도 코로나19로 인해 우울감이 컸는데 웃을 수 있었다.”라며 감사의 마음을 표현하였다. \\n\\n \\n\\n 청소년동반자는 위기 청소년들에게 개인별 맞춤형 찾아가는 상담뿐만 아니라 복지 자원을 발굴하여 제공하는 등 청소년들의 현장에서 활동하고 있다. \\n\\n \\n\\n 청소년의 대인관계, 진로 및 심리 상담 서비스가 필요한 경우 부산 서구 청소년상담복지센터 또는 청소년 전화 1388로 문의하여 상담을 신청하면 된다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\",\n",
       " \"<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 맹형규 행안부 장관은 공직기강 확립을 위해 어떤 제목의 서한문을 전 직원들에게 발송했지\\n선택지: ['행안부 가족에게 드리는 글', '공직기강 확립 실천계획', '청렴서약서', '긴급 확대간부회의']\\n\\n행안부 긴급확대간부회의를 개최,「공직기강 확립 및 윤리 실천계획」추진키로 \\n□ 맹형규 행정안전부 장관은 6월 22일(수) 오전 “공직기강 확립을 위한 긴급 확대간부회의”를 개최하고\\n○ 행정안전부 전 직원들에게 공직 내 오랫동안 잠재된 낡은 관행과 악습을 청산하는데 앞장서 줄 것을 당부했다. \\n□ 최근 공직기강 해이에 대해 사회전반에 걸쳐 우려의 목소리가높아지는 가운데\\n○ 지난 6월 16일(목) “행안부 가족에게 드리는 글”이라는 장관 서한문을 전 직원들에게 발송하여 공직기강 확립을 당부한데 이어, \\n○ 당초 다음 달 초에 예정되어 있던 확대간부회의를 6월 22일로 앞당겨 “공직기강 확립 실천계획”을 긴급 보고하도록 한 것이다. \\n□ 이날 회의에서는\\n○ 행안부 본부, 정부청사관리소․정부통합전산센터 등 소속기관, 경찰청 ․ 소방방재청 등 기관별로 공직기강 확립을 위한 실천 대책을 발표했다. \\n○ 아울러, 국장급 이상 간부공무원 27명은 “청렴서약서”를 작성해 맹형규 장관에게 직접 전달했다\\n□ 특히, 맹형규 장관은 이날 회의를 통해\\n○ “그간 당연시되어 온 공직 내 관행들도 냉철하게 돌아보고 공직 사회가 새롭게 변모하는 계기를 만들어야 할 것”이라고 강조했다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\",\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 문장의 요지를 알려줘.\\n\\n현재 기술자가 퇴사후에 직권으로 자격증 해임을 하기 위해서는 민법상 규정을 적용해 \"내용증명방식으로 의사를 보내고 30일 이후에 기술자가 협회에 방문제출\" 할 경우만 직권퇴사를 인정하고 있습니다. 이런 점을 노려 회사들은 조금만 기다려 달라는 말을 하며 근로자들을 기다리게 하면서 동등 자격증을 가진 사람을 구하기 쉽지않다며 퇴사처리를 늦게 해주고 있습니다. 근로자의 입장에서는 끌려다닐수 밖에 없는 입장입니다. 그후 근로자가 더이상 기다릴수 없어 법적인 절차를 하려하면 위의 절차에 따라 또 1달의 기간을 기다리게 됩니다. 이런 제도적인 허점이 의도하지 않은 서류상 이중취업, 자격증 불법대여가 되게 됩니다. 4대보험의 퇴사관련 서류를 구비할경우 1주일이내에 각 협회(건설, 전기, 통신, 소방... 등)에서 온라인으로 자격증 직권해임이 되게끔 행정절차를 개선할 필요가 있다고 생각합니다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 글에서 핵심만 요약해줘.\\n\\n해양 녹색기술(green technology)개발은 재생가능하고 환경친화적 방식의 과학기술을 해양에서 적용하려는 시도이다. 국가와 민간 사업체들은 해상 풍력발전, 해양 바이오에너지 생산 및 해양시비에 큰 관심을 갖고 있다. 현재 대다수의 해양 녹색기술은 아직 상용화에 앞서 실험, 연구하는 개발 초기단계로서, 이러한 상황에서 제기될 수 있는 주요 국제법적 쟁점은 두 가지이다. 첫 번째 쟁점은 해양 녹색기술 실험행위를 어떠한 해양활동으로 이해할 것인가이다. 유엔해양법협약은 해양과학조사에 대하여 구체적인 제한을 부과하지 않고 있기 때문에, 녹색기술 실험은 큰 문제없이 해양과학조사로 볼 수 있다. 반면, 최근 런던덤핑협약체제와 생물다양성협약 당사국회의의 결정은 해양 녹색기술을 수반한 과학조사의 규모, 장소 및 목적을 제한하고자 한다. 이와 같은 당사국회의의 결정은 기존의 해양과학조사 개념을 변화시키지 않지만, 과학조사 수행시 국가들이 고려할 수 있는 행동지침의 역할을 하게 된다. 둘째, 해양 녹색기술이 해양환경에 미치는 영향은 과학적으로 충분히 입증되지 않았다. 이와 같이 과학적 불확실성이 존재하는 경우, 사전주의원칙이 적용될 수 있다. 문제는 여러 조약상의 사전주의원칙이 서로 다르게 해석될 수 있다는 점이다. 따라서 사전주의원칙은 해양 녹색기술개발을 정당화하는 동시에, 개발을 막는 근거가 될 수 있다. 하지만 사전주의원칙을 사전주의적 조치를 요구하는 행위규칙이 아닌 절차적 기준으로 해석한다면, 협약간 모순된 법적 의무가 창출된다는 우려를 해소할 수 있다. 또한 다수 조약상의 사전주의원칙을 해석할 때, 조약법에 관한 비엔나협약 제31조 3항(c)과 조약간 조화로운 해석원칙에 따른다면, 해석상의 충돌 문제를 방지할 수 있을 것이다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: This is most likely a result of cultural differences between the US and the UK.\\nto Korean:<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: stress fracture\\nto Korean:<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 개념에 대해 설명해줘. \\n\\n울혈성심장기능상실<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " \"<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 아래 사건의 사실 관계를 읽고 어떤 법 조항이 적용될 수 있는지 알려줘.\\n\\n피고인은 (차량번호 1 생략) 포터 화물차의 운전업무에 종사하는 자이다. 피고인은 2019. 12. 19. 13:40경 익산시 B 사거리를 ‘익산세무소' 방면에서 ‘C' 방면으로 알 수 없는 속도로 좌회전하게 되었다. 그곳은 전방에 횡단보도가 설치되어 있으므로 이러한 경우 자동차의 운전업무에 종사하는 자로서는 속도를 줄이고 전방 및 좌우를 잘 살펴 길을 건너는 사람이 있는지 여부를 확인하고 안전하게 운전하여야 할 업무상 주의의무가 있었다. 그럼에도 불구하고 피고인은 이를 게을리 한 채 만연히 좌회전한 과실로 피고인 진행방향의 오른쪽에서 왼쪽으로 횡단보도를 건너가던 피해자 D(남, 85세)을 미처 발견하지 못하고 위 화물차의 앞 범퍼로 피해자의 좌측면을 들이받아 도로에 넘어지게 하였다. 이로써 피고인은 위와 같은 업무상의 과실로 피해자로 하여금 사고발생일인 2019. 12. 19.경부터 2020. 4. 3. 06:15경까지 병원 치료를 받던 중, 2020. 4. 3. 06:15경 성남시 분당구 E에 있는 F병원에서 급성신부전으로 사망에 이르게 하였다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\",\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 저희 종중은 선산에 20여분의 조상을 모시고 있으나 분묘를 관리할 위토(位土)는 한 평도 없는 상태이므로, 위토로 사용하기 위하여 인근에 있는 밭이나 논을 구입하고자 합니다. 이 경우 종중명의로 구입할 수 있는지요?\\n\\n해당 질문에 대해 법률 자문을 해주세요.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 판결문 핵심만 요약해줘.\\n\\n주문\\n피고인의 상고를 기각한다.\\n\\n이유\\n상고이유를 본다.\\n1. 피고인이 시장 또는 군수의 허가없이 근린생활 시설인 이 사건 건축물을 교회로 용도변경 사용한 행위는 1987년부터 비로소 처벌대상이 된 것이 아니라 피고인이 위 용도변경사용행위를 시작한 1985.9.1. 당시에도 그 당시의 건축법 제54조 제1항, 제5조 제1항 본문, 제48조에 위반되는 행위로서 처벌대상이 되었음이 명백하고, 또한 형법 제16조에 자기의 행위가 법령에 의하여 죄가 되지 아니하는 것으로 오인한 행위는 그 오인에 정당한 이유가 있는 때에 한하여 처벌하지 아니한다고 규정하고 있는 것은 단순한 법률의 부지의 경우를 말하는 것이 아니고, 일반적으로 범죄가 되는 행위이지만 자기의 특수한 경우에는 법령에 의하여 허용된 행위로써 죄가 되지 아니한다고 그릇 인식하고 그와 같이 인식함에 있어 정당한 이유가 있는 경우에는 벌하지 아니한다는 취지이므로, 피고인이 이 사건 행위가 건축법상의 허가대상인 줄을 몰랐다는 사정은 단순한 법률의 부지에 불과하고 특히 법령에 의하여 허용된 행위로써 죄가 되지 않는다고 적극적으로 그릇 인식한 경우가 아니어서 이를 법률의 착오에 기인한 행위라고 할 수도 없다. 논지는 이유없다.\\n2. 피고인에게 벌금형이 선고된 이 사건에 있어서 양형부당의 사유는 적법한 상고이유가 되지 못한다. 논지는 이유없다.\\n그러므로 상고를 기각하기로 관여 법관의 의견이 일치되어 주문과 같이 판결한다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 법의 내용이 뭔지 알려줘.\\n\\n도로교통법 제12조 제5항 제3호<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 개념에 대해 설명해줘. \\n\\n수출보험<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 당신은 사람들이 정보를 찾을 수 있도록 도와주는 AI 비서입니다. \\n\\n단순반복동작 작업으로 손, 손가락 또는 손목의 부적절한 작업방법과 자세 등으로 주로 손목 부위에 주로 발생하는 근골격계질환은?\\nA: 테니스엘보\\nB: 회전근개손상\\nC: 수근관증후군\\nD: 흉곽출구증후군<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " \"<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**:  \\n\\n왜 그 노래가 '푸른 도나우'라고 불리나요?<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\",\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 문서에서 이 질문에 대한 답을 알려줄래?\\n\\n맥락: 오산학교(五山學校)는 1907년 12월 남강(南崗) 이승훈(李昇薰)이 민족운동의 인재와 국민교육의 사표(師表)를 양성할 목적으로 평안북도 정주에 세운 학교이다.[1], 질의: 오산학교는 언제 세워졌나요?<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " \"<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음과 같이 문단과 질문이 주어졌을 때 질문의 답을 추론해주세요.\\n\\n문단: 카페 아메리카노 또는 단순히 아메리카노는 에스프레소를 뜨거운 물로 희석하여 마시는 커피 음료의 한 종류이다. 그 농도는 일반적인 드립 커피와 비슷하지만 풍미는 다르다. 아메리카노의 농도는 에스프레소의 '샷' 수와, 더해지는 물의 양에 따라 달라진다. / 질문: 카페 아메리카노는 드립커피와 풍미가 비슷하다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\",\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음과 같이 두 문장이 주어졌을 때 둘의 관계를 추론해주세요.\\n\\n문장1: 73조5000억원 규모로 마련된 금융시장 안정 프로그램에선 12조6000억원의 집행 실적을 기록했다., 문장2: 금융시장 안정 프로그램은 73조 5000억 원 규모로 마련됬다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 산술 연산 문제의 답을 알려줘.\\n\\n어떤 수를 6으로 나누어야 할 것을 잘못하여 곱하였더니 36이 되었습니다. 바르게 계산하면 얼마입니까?<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 두 문장이 같은 의미를 나타내나요?\\n\\n난방비 비싼데 추워, 가스비 비싼데 감기 걸리겠어<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 선택지:\\n&&정치개혁&&문화/예술/체육/언론&&인권/성평등&&보건복지&&기타&&미래&&외교/통일/국방&&농산어촌&&교통/건축/국토&&행정&&육아/교육&&일자리&&경제민주화&&저출산/고령화대책&&성장동력&&안전/환경&&반려동물&&\\n이 중 아래 청원이 무슨 카테고리에 속하는 지 알려주세요.\\n\\n언론사들은 이 번 대통령의 방중에 대하여 국민들이 스스로 판단하고 결정할 권리를 방해 하였습니다. 법에 대하여 잘 알지 못하는 저로서는 국가의 도움을 받아 저의 권리를 찾고 싶습니다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 신문 기사의 주제를 알려줘.\\n\\nLH 아파트 최근 3년간 공급 아파트에서 하자 2만4천여건<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 문장이 긍정적인 문장인지 부정적인 문장인지 알려줘.\\n\\n개인적인 의견이지만 끝에 뭔가 큰 반전이 있을줄 알고 봐서 그런지 그냥 밍숭맹숭하네요...<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>',\n",
       " '<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음과 같이 두 문장이 주어졌을 때 입력된 단어가 같은 의미로 쓰이는지 파악해주세요.\\n\\n단어: 성화, 문장1: 새살림을 차렸으니 집들이하라는 주변의 [성화]가 대단하다., 문장2: 김 노인은 땅을 팔라는 사람들의 [성화]에도 끝끝내 내버텼다.<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04f3c1ae-cefd-4e37-844a-e999048342d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 파일 저장하려면\n",
    "with open('gen_config_prompt.pickle', \"wb\") as f:\n",
    "    pickle.dump(ds_sample, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbcab8-f8ce-4858-93cf-8f413a22ec80",
   "metadata": {},
   "source": [
    "## 2. 평가용 프롬프트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ff994be-372d-4a95-b6e8-bebb2921fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 프롬프트 파일 불러오려면\n",
    "with open('gen_config_prompt.pickle', \"rb\") as f:\n",
    "    ds_sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad288f0-b4d8-4607-8f14-7f81d994010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 이 개념에 대해 설명해줘. \\n\\n황학 (명나라)<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d074b-46b6-466c-b211-eb57bfbc8084",
   "metadata": {},
   "source": [
    "cf. 훈련 시 사용한 템플릿 적용 결과\n",
    "- assistant 뒤에 데이터의 output 칼럼 값 들어감\n",
    "```\n",
    "\"\"\"'<|start_header_id|>system<|end_header_id|>\\n        당신의 역할은 한국어로 답변하는 **한국어 AI 어시트턴트**입니다. 주어진 질문에 대해 한국어로 답변해주세요.<|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        아래 질문을 한국어로 정확하게 답변해주세요. **질문**: 다음 단어를 정의 중심으로 설명해주세요.\\n\\n황학 (명나라)<|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\\n\\n황학(黃鶴)는 명나라 중기의 정치인이었다. 자(字)는 명고(鳴臯)이다. 하남성(河南省) 개봉부(開封府) 기현(杞縣) 출신이다.<|eot_id|>\\n        <|end_of_text|>'\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b687dc-6956-495d-af31-e5bb642aa972",
   "metadata": {},
   "source": [
    "## 3. 프롬프트 & 생성옵션 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae23d144-db8d-4d5a-aea9-695a3d180fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):    \n",
    "    # -> config.py에서 설정한 시드가 모델훈련 등 다른 모듈에도 적용되는지 체크 필요\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "\n",
    "def load_model(model_path, peft):\n",
    "    if peft: # lora 훈련 모델\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        config = PeftConfig.from_pretrained(model_path) # 훈련시킨 어댑터 로드 # LoraConfig\n",
    "        model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        model = PeftModelForCausalLM.from_pretrained(model, model_path)\n",
    "\n",
    "    else: # default 훈련 모델\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.bfloat16, \n",
    "            low_cpu_mem_usage=True,\n",
    "            device_map=\"auto\")\n",
    "\n",
    "    setattr(model, 'model_parallel', True)\n",
    "    setattr(model, 'is_parallelizable', True)\n",
    "    model.config.use_cache = False \n",
    "    model.config.pretraining_tp = 1\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(model_path):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd83dccc-6141-483e-8de8-c67343c464f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmcho/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd02d5e1f260429484c63c2c1d3d1b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer): 128256\n"
     ]
    }
   ],
   "source": [
    "# 기본 설정\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "set_seed(seed=1) # 시드 고정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 모델 불러오기\n",
    "# 모델 로드 안되는 경우 : 터미널에서 huggingface-cli login 실행 후 access token 입력\n",
    "model = load_model(model_name_or_path, peft=False)\n",
    "tokenizer = load_tokenizer(model_name_or_path)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(\"len(tokenizer):\", len(tokenizer))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "490e2db4-9bc9-4560-98dd-1f1fbf21e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9bb09a-f75e-4135-8a07-456b90ecf460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 값 조정하기\n",
    "gen_config = {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.8, 'top_p': 1.0, 'top_k': 5, 'no_repeat_ngram_size': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61557674-9059-406c-babe-e464b541278a",
   "metadata": {},
   "source": [
    "* 참고사항\n",
    "\n",
    "1. 정성평가 코드에서 설정된 기본값 (24-07-25 기준)\n",
    "```\n",
    " 'generation config': {'max_new_tokens': 256, 'do_sample': True, 'temperature': 1.0, 'top_p': 1.0, 'top_k': 5, 'no_repeat_ngram_size': 0}\n",
    "```\n",
    "\n",
    "2. 정성평가에서 현재 사용하는 hyperparameter 값\n",
    "```\n",
    " 'generation config': {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.8, 'top_p': 1.0, 'top_k': 5, 'no_repeat_ngram_size': 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c53bf22a-901c-483f-a5c6-7b5b4398014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 프롬프트에 대해 output 생성시키기\n",
    "def get_gen_results(gen_config, prompts):\n",
    "    responses = []\n",
    "    batched_inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        outputs = model.generate(**batched_inputs, **gen_config)\n",
    "        print(f\"=========================== total generation took {time.time()-start_time:.2f} sec. ===========================\")\n",
    "        response = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        responses.append(response)\n",
    "        \n",
    "    return responses  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c838030-f3be-4861-bb60-61ffc6d19f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_gen_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mget_gen_result\u001b[0;34m(gen_config)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m ds_sample[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     outputs_all\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1174\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:978\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    967\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    968\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    969\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         cache_position,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:718\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:622\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    620\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 622\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/model_train_py39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:118\u001b[0m, in \u001b[0;36mLlamaRotaryEmbedding.forward\u001b[0;34m(self, x, position_ids)\u001b[0m\n\u001b[1;32m    116\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m (inv_freq_expanded\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m@\u001b[39m position_ids_expanded\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    117\u001b[0m     emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((freqs, freqs), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m     cos \u001b[38;5;241m=\u001b[39m \u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     sin \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39msin()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cos\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype), sin\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 생성 테스트 (-> colab A100 GPU, llama3 기준으로 총 17초 소요) \n",
    "result = get_gen_results(gen_config, ds_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2ea1f-6612-49c3-80cd-170dc742ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in result:\n",
    "    print(item)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
